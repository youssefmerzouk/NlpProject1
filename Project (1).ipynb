{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data = pd.read_csv(\"sentences.csv\")\n",
    "data = data.dropna()\n",
    "data['english'] = data['eng']\n",
    "english_sentences = data['english'].tolist()\n",
    "darija_sentences = data['darija'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train, validation, and test sets\n",
    "train_eng, temp_eng, train_dar, temp_dar = train_test_split(english_sentences, darija_sentences, test_size=0.2)\n",
    "val_eng, test_eng, val_dar, test_dar = train_test_split(temp_eng, temp_dar, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src shape: torch.Size([32, 50])\n",
      "trg shape: torch.Size([32, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_24272\\3366960100.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  {key: torch.tensor(val[idx]) for key, val in self.encodings.items()},\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_24272\\3366960100.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[\"input_ids\"][idx])\n"
     ]
    }
   ],
   "source": [
    "#initialize tokenizer for both English and Darija (using a multilingual model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
    "\n",
    "#tokenize the sentences\n",
    "train_encodings = tokenizer(train_eng, padding=True, truncation=True, return_tensors=\"pt\", max_length=50)\n",
    "train_labels = tokenizer(train_dar, padding=True, truncation=True, return_tensors=\"pt\", max_length=50)\n",
    "\n",
    "#dataset class\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            {key: torch.tensor(val[idx]) for key, val in self.encodings.items()},\n",
    "            torch.tensor(self.labels[\"input_ids\"][idx])\n",
    "        )\n",
    "\n",
    "#create the Dataset and DataLoader\n",
    "train_dataset = TranslationDataset(train_encodings, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#check the first batch to confirm it's working\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    src, trg = batch\n",
    "    print(f\"src shape: {src['input_ids'].shape}\")\n",
    "    print(f\"trg shape: {trg.shape}\")\n",
    "    break  # Print just the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_24272\\3366960100.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  {key: torch.tensor(val[idx]) for key, val in self.encodings.items()},\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_24272\\3366960100.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(self.labels[\"input_ids\"][idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.595041040342803\n",
      "Epoch 2, Loss: 4.91170379883817\n",
      "Epoch 3, Loss: 4.692343031724793\n",
      "Epoch 4, Loss: 4.505145769507908\n",
      "Epoch 5, Loss: 4.320055384620978\n",
      "Epoch 6, Loss: 4.137181234210263\n",
      "Epoch 7, Loss: 3.9512719517591233\n",
      "Epoch 8, Loss: 3.759408745272406\n",
      "Epoch 9, Loss: 3.5723355309716585\n",
      "Epoch 10, Loss: 3.393462480796168\n"
     ]
    }
   ],
   "source": [
    "#define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hidden_dim, dropout_rate=0.3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        outputs = self.dropout(outputs)\n",
    "        predictions = self.fc(outputs)\n",
    "        return predictions\n",
    "\n",
    "#initialize the model with the correct vocab size\n",
    "vocab_size = tokenizer.vocab_size\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMModel(input_dim=vocab_size, output_dim=vocab_size, emb_dim=256, hidden_dim=512).to(device)\n",
    "\n",
    "#adamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)  # Ignore padding token during loss calculation\n",
    "\n",
    "#learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "\n",
    "#gradient clipping\n",
    "clip_value = 1.0\n",
    "\n",
    "#tensorBoard for monitoring\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#training loop\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        #unpack the batch\n",
    "        src, trg = batch\n",
    "        \n",
    "        #move tensors to the device\n",
    "        src = src[\"input_ids\"].to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass\n",
    "        output = model(src)\n",
    "        \n",
    "        #flatten the output and target for loss calculation\n",
    "        output = output.view(-1, output.shape[-1])  # Flatten to [batch_size * seq_len, vocab_size]\n",
    "        trg = trg.view(-1)  # Flatten target to [batch_size * seq_len]\n",
    "\n",
    "        #mask padding tokens\n",
    "        mask = trg != tokenizer.pad_token_id  # Mask padding tokens from target\n",
    "        output = output[mask]  # Apply the mask to output\n",
    "        trg = trg[mask]  # Apply the mask to target\n",
    "        \n",
    "        #compute loss\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()  # Backpropagation\n",
    "        \n",
    "        #gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        \n",
    "        optimizer.step()  # Update model parameters\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    #adjust the learning rate using scheduler\n",
    "    scheduler.step(epoch_loss)\n",
    "    \n",
    "    #log loss to TensorBoard\n",
    "    writer.add_scalar('Loss/train', epoch_loss / len(train_loader), epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "#close TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Translation Test (Type 'exit' to quit)\n",
      "English: Thank you for your help.\n",
      "Translated (Darija): chokran 3la la\n",
      "--------------------------------------------------\n",
      "English: Thank you for your help.\n",
      "Translated (Darija): chokran 3la lla\n",
      "--------------------------------------------------\n",
      "English: Thank you for your help.\n",
      "Translated (Darija): chokran 3la 3 l\n",
      "--------------------------------------------------\n",
      "English: Thank you for your help.\n",
      "Translated (Darija): chokran 3lik la\n",
      "--------------------------------------------------\n",
      "English: They're hiding something, I'm sure!\n",
      "Translated (Darija): rah kaybby ha ,,,a7\n",
      "--------------------------------------------------\n",
      "English: They're hiding something, I'm sure!\n",
      "Translated (Darija): gha kaybby ha7,,,,a\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#initialize tokenizer and model (assuming they are already defined and trained)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#function to generate translations\n",
    "def generate_translation(model, tokenizer, sentence, device):\n",
    "    #tokenize the input sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=50).to(device)\n",
    "    \n",
    "    #generate translation using the model\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs[\"input_ids\"])  # Get model output\n",
    "        pred_tokens = torch.argmax(output, dim=-1)  # Get the index of the highest probability token for each position\n",
    "        \n",
    "    #decode the predicted tokens to get the translated sentence\n",
    "    pred_sentence = tokenizer.decode(pred_tokens[0], skip_special_tokens=True)\n",
    "    return pred_sentence\n",
    "\n",
    "# Start interactive loop\n",
    "print(\"Interactive Translation Test (Type 'exit' to quit)\")\n",
    "while True:\n",
    "    #ask for user input\n",
    "    input_sentence = input(\"Enter an English sentence: \")\n",
    "    \n",
    "    #exit condition\n",
    "    if input_sentence.lower() == \"exit\":\n",
    "        print(\"Exiting interactive mode.\")\n",
    "        break\n",
    "    \n",
    "    #generate the translation\n",
    "    translated_sentence = generate_translation(model, tokenizer, input_sentence, device)\n",
    "    \n",
    "    #output the result\n",
    "    print(f\"English: {input_sentence}\")\n",
    "    print(f\"Translated (Darija): {translated_sentence}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
